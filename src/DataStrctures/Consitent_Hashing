# ‚úÖ 1. What is Consistent Hashing? (Explained Like a Teacher)

### **Imagine:**

You have **3 pani-puri stalls** (servers).
Customers (keys) must go to the same stall always.

Normally you do:

```
stall = hash(customerId) % numberOfStalls
```

But if one stall breaks or a new stall is added:

* All customers get redistributed
* Huge load movement
* Cache gets cold
* System becomes unstable

This is BAD at scale.

### ‚ö° **Consistent Hashing fixes this problem**

‚úî When a server joins ‚Üí **very few keys move**
‚úî When a server leaves ‚Üí **very few keys move**
‚úî No full rehashing
‚úî Perfect for distributed real-time systems

---

# ‚úÖ 2. Where is Consistent Hashing used in real systems?

### **Real-time uses**

| System                                   | How it uses consistent hashing                  |
| ---------------------------------------- | ----------------------------------------------- |
| **CDNs** (Cloudflare / Akamai)           | Map requests to nearest caching server          |
| **Distributed Cache** (Redis, Memcached) | Spread keys across nodes                        |
| **DynamoDB / Cassandra**                 | Partition data across multiple nodes            |
| **Load Balancers**                       | Route specific clients to specific backend pods |
| **Distributed logs** (Kafka, Pulsar)     | Partition selection using consistent hashing    |

---

# ‚úÖ 3. The Core Idea (Explained in 20 seconds)

### **We draw a circle (ring).**

* All servers are placed on the ring using hash(serverId)
* All keys are placed on the ring using hash(key)
* A key is stored in the **next server clockwise**

### üìò ASCII Diagram (Stick Diagram)

```
                    (Server A)
                        |
                        |
            (Key X) ---   ---- (Key Y)
                     \        /
                      \      /
                       \    /
(Server D)------------- RING ---------------(Server B)
                       /    \
                      /      \
                     /        \
            (Key Z) ----    ----  (Key P)
                        |
                        |
                    (Server C)
```

### How lookup works?

Example:
hash("Key X") ‚Üí lands here ‚Üí go clockwise ‚Üí nearest server = **Server A**

---

# ‚úÖ 4. Why does data movement reduce?

Suppose a server joins (Server E):

```
Before:
A ---- B ---- C ---- D ---- A (ring)

After adding E:
A ---- B ---- C ---- D ---- E ---- A
```

Only **the keys between D ‚Üí E** move.
Not ALL keys.

This is the **magic sauce**.

---

# ‚ö° 5. Why do we need Virtual Nodes? (Very important for interviews)

Servers might have different capacities.

Example:

* Big server can hold 100GB
* Small server only 10GB

To avoid imbalance ‚Üí each server gets multiple virtual positions on the ring.

ASCII Diagram:

```
     A1     B1     C1     A2     B2     C2
      |      |      |      |      |      |
------o------o------o------o------o------o------ (Ring)
```

So load is **evenly spread**.

---

# ‚úÖ 6. Relation to CAP Theorem (Simple Teaching)

**CAP theorem** says:

> In a distributed system, you can choose **2 out of 3**
> **C = Consistency**
> **A = Availability**
> **P = Partition Tolerance**

### Where does Consistent Hashing fit?

Consistent hashing is used when the system wants:

* **High Availability** ‚Üí (if 1 node dies, others still have data)
* **Partition Tolerance** ‚Üí (network breaks? still route to nearest server)

So most systems using consistent hashing (Cassandra, DynamoDB) choose:

### ‚û§ **AP system**

‚ùå Consistency is eventually achieved
‚úî Availability always maintained
‚úî Partition tolerance handled

---

# üèó 7. Small System Design (Teacher Explanation)

Let‚Äôs design a tiny distributed cache using consistent hashing.

---

## Step 1: **Create Ring**

Use a hash function (SHA-1 or MurmurHash)

```
0 ‚Üí 2^32 (full range)
```

---

## Step 2: **Add servers to ring**

Compute hash(serverId)

```
Server A ‚Üí at 3000
Server B ‚Üí at 11000
Server C ‚Üí at 24000
```

ASCII Diagram:

```
                3000 (A)
                   |
                   |
0 --------------------------------------- 24000 (C)
                   |
                   |
                11000 (B)
```

---

## Step 3: **Store keys**

keyOwner = firstServerClockwise(hash(key))

Example:

```
hash("student1") ‚Üí 3500 ‚Üí goes to A  
hash("student2") ‚Üí 12000 ‚Üí goes to B  
hash("student3") ‚Üí 25000 ‚Üí goes to C  
```

---

## Step 4: **When server joins?**

Example: D at 5000

Only keys between A(3000) ‚Üí D(5000) move.

---

## Step 5: **When server leaves?**

Example: remove B at 11000

All B‚Äôs keys go to **nearest clockwise server**, i.e., C.

---

# ‚ú® Stick Diagram: Add/Remove Server

### Adding Server D

```
Before: A ------- B ------------ C --------- A

After:  A --- D -- B ------------ C --------- A
```

Only between A ‚Üí D moves.

### Removing Server B

```
Before: A --- D --- B --- C --- A

After:  A --- D -------- C --- A
```

Only B‚Äôs keys move to C.

---

# ‚öñ 8. Trade-Offs (Simple One-Liners)

| Feature                            | Advantage                           | Tradeoff                                  |
| ---------------------------------- | ----------------------------------- | ----------------------------------------- |
| **Reduced rehashing**              | Only a few keys move                | Slightly complex implementation           |
| **High availability**              | Node failures don‚Äôt kill the system | Eventual consistency if AP system         |
| **Load balancing (virtual nodes)** | Smooth distribution                 | Uses more memory for ring mapping         |
| **Scalability**                    | Add/remove nodes freely             | Hard debugging / ring partitioning issues |
| **Fast lookup**                    | O(log N) with binary search         | Needs careful hash function selection     |

---

# üß† 9. Tiny Implementation View (Pseudo-code)

```js
/**
 * ConsistentHashing class
 * ------------------------
 * This class represents a simple Consistent Hashing implementation.
 * It uses:
 *  - A ring (sorted array of hash values)
 *  - Virtual nodes to improve load distribution
 *  - A hash function (you can plug in MurmurHash or any 32-bit hash)
 *
 * Why OOP?
 * --------
 * - "Encapsulation": all hashing logic stays inside the class
 * - "Abstraction": caller doesn't know ring implementation
 * - "Extensibility": easy to add replication, remove nodes, etc.
 */

class ConsistentHashing {
  constructor(virtualNodes = 10) {
    // The ring will store an array of { hash: number, serverId: string }
    // This acts like the circular ring in consistent hashing.
    this.ring = [];

    // Each server will be represented multiple times to balance load.
    this.virtualNodes = virtualNodes;
  }

  /**
   * A simple placeholder hash function.
   * In real systems, use MurmurHash, SHA-1, md5, etc.
   * 
   * Why hash function?
   * - To map keys and servers uniformly on the hash ring.
   */
  hashFn(key) {
    // Very basic hash function for demonstration (not cryptographically strong)
    let hash = 0;
    for (let i = 0; i < key.length; i++) {
      hash = (hash * 31 + key.charCodeAt(i)) % 100000; // keep inside range
    }
    return hash;
  }

  /**
   * addServer(serverId)
   * -------------------
   * Adds a server to the ring.
   * Adds N virtual nodes to balance load.
   * Re-sorts the ring to maintain clockwise traversal.
   */
  addServer(serverId) {
    for (let i = 0; i < this.virtualNodes; i++) {
      // Create a virtual node id (serverA#0, serverA#1, etc.)
      const virtualNodeId = `${serverId}#${i}`;

      // Hash this virtual node to find its position on ring
      const hash = this.hashFn(virtualNodeId);

      // Add to ring
      this.ring.push({ hash, serverId });
    }

    // Important: The ring must always be sorted by hash to simulate "clockwise"
    this.ring.sort((a, b) => a.hash - b.hash);
  }

  /**
   * getServer(key)
   * ---------------
   * Finds which server owns the given key.
   *
   * Steps:
   * 1. Hash the key
   * 2. Move clockwise and find the first server whose hash >= keyHash
   * 3. If none found, wrap around ‚Üí return ring[0]
   */
  getServer(key) {
    // Step 1: Compute key hash
    const keyHash = this.hashFn(key);

    // Step 2: Linear search (can be replaced with binary search)
    // We find the "first server clockwise"
    for (let node of this.ring) {
      if (node.hash >= keyHash) {
        return node.serverId;
      }
    }

    // Step 3: Wrap-around ‚Äî when key hash is greater than all node hashes
    return this.ring[0].serverId;
  }

  /**
   * removeServer(serverId)
   * -----------------------
   * Removes all virtual nodes of the given server.
   *
   * Why do we need this?
   * - To simulate node failures or scaling down.
   */
  removeServer(serverId) {
    // Keep only those nodes which are NOT from this server
    this.ring = this.ring.filter(node => node.serverId !== serverId);

    // Re-sort ring (not mandatory, but good practice)
    this.ring.sort((a, b) => a.hash - b.hash);
  }
}

// -----------------------------------------------
// Example Usage
// -----------------------------------------------

// Create consistent hashing with 5 virtual nodes per server
const ch = new ConsistentHashing(5);

// Add servers
ch.addServer("ServerA");
ch.addServer("ServerB");
ch.addServer("ServerC");

// Lookup keys
console.log("Key1 -> ", ch.getServer("Key1"));
console.log("Key2 -> ", ch.getServer("Key2"));
console.log("Key3 -> ", ch.getServer("Key3"));

// Remove server
ch.removeServer("ServerB");

console.log("After removing ServerB:");
console.log("Key1 -> ", ch.getServer("Key1"));
console.log("Key2 -> ", ch.getServer("Key2"));
console.log("Key3 -> ", ch.getServer("Key3"));

```

---

# üéâ Final Summary (Like a Teacher)

* Consistent Hashing = Smart way to distribute data **that avoids full rehashing**
* Used in: CDNs, Caches, DynamoDB, Cassandra, load balancers
* Uses a **ring** + **hash function**
* Keys go to **next server clockwise**
* Adding/removing servers moves **minimal keys**
* Virtual nodes ‚Üí balance load
* Fits **AP** systems in CAP theorem
* Very scalable and fault-tolerant

---

If you want, I can also:
‚úÖ Draw **more diagrams**
‚úÖ Design **full HLD + LLD**
‚úÖ Provide **JS implementation with comments**
‚úÖ Provide **interview-ready 2-minute explanation**
